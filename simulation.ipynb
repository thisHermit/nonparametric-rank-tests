{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c3919f7-dc75-4a2a-b7df-ad6009667f5b",
   "metadata": {},
   "source": [
    "# Simulation details\n",
    "\n",
    "* Both are normal distributions\n",
    "\n",
    "# Expectations\n",
    "\n",
    "* p value should be less than $\\alpha$ when the distributions are different"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28252b1d-e442-446d-80bf-e7835419e6d4",
   "metadata": {},
   "source": [
    "# Normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fa4fc9-424a-4e71-8884-b5afb7828e73",
   "metadata": {},
   "source": [
    "## Same variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b7be7d1-9175-46f1-a4b8-e33384c36fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mannwhitneyu, norm, rankdata, wilcoxon, cauchy\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4442b28b-a078-4cd2-a77d-047a4e2305c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65dbf501-65e3-483a-b2c9-9a1355dc949c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21f86e08c4247338394e7f00bc0d3e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=50.0, description='Mean 1', step=1.0), FloatSlider(value=55.0, descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_interactive_mannwhitneyu(mean1=50, mean2=55, std_dev=10, size=100)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_interactive_mannwhitneyu(mean1=50, mean2=55, std_dev=10, size=100):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    sample1 = np.random.normal(loc=mean1, scale=std_dev, size=size)\n",
    "    sample2 = np.random.normal(loc=mean2, scale=std_dev, size=size)\n",
    "    \n",
    "    stat, p_value = mannwhitneyu(sample1, sample2, alternative='two-sided')\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(sample1, bins=20, alpha=0.7, label=f'Sample 1 (Mean={mean1})', color='blue', edgecolor='black')\n",
    "    plt.hist(sample2, bins=20, alpha=0.7, label=f'Sample 2 (Mean={mean2})', color='orange', edgecolor='black')\n",
    "    plt.axvline(np.mean(sample1), color='blue', linestyle='dashed', linewidth=1)\n",
    "    plt.axvline(np.mean(sample2), color='orange', linestyle='dashed', linewidth=1)\n",
    "    plt.title(\"Histogram of Sample 1 and Sample 2\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figtext(0.15, 0.75, f\"Wilcoxon Mann-Whitney Test\\nStatistic: {stat:.2f}\\nP-value: {p_value:.4f}\", \n",
    "                fontsize=10, color=\"black\", bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "interact(plot_interactive_mannwhitneyu, \n",
    "         mean1=widgets.FloatSlider(value=50, min=0, max=100, step=1, description='Mean 1'),\n",
    "         mean2=widgets.FloatSlider(value=55, min=0, max=100, step=1, description='Mean 2'),\n",
    "         std_dev=widgets.FloatSlider(value=10, min=1, max=30, step=1, description='Std Dev'),\n",
    "         size=widgets.IntSlider(value=300, min=100, max=500, step=50, description='Sample Size'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cd8576-176e-4e78-8379-551bda7ca88d",
   "metadata": {},
   "source": [
    "## Different Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f5f0d05-5d46-488e-9869-f564612e3496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e756afeda0fa4f6598d135895377c77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=50.0, description='Mean 1', step=1.0), FloatSlider(value=0.0, descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_interactive_tests(mean1=50, delta=0, std_dev1=10, std_dev2=10, size=100, signif_alpha=0.05, runs=100)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_interactive_tests(mean1=50, delta=0, std_dev1=10, std_dev2=10, size=100, signif_alpha=0.05, runs=100):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    mean2 = mean1 + delta\n",
    "    mw_p_values, waerden_p_values, median_test_p_values = [], [], []\n",
    "    fy_p_values, perm_p_values, tstt_p_values = [], [], []\n",
    "    \n",
    "    for _ in range(runs):\n",
    "        sample1 = np.random.normal(loc=mean1, scale=std_dev1, size=size)\n",
    "        sample2 = np.random.normal(loc=mean2, scale=std_dev2, size=size)\n",
    "    \n",
    "        stat_mw, p_value_mw = mannwhitneyu(sample1, sample2, alternative='two-sided')\n",
    "        combined = np.concatenate([sample1, sample2])\n",
    "        ranks = rankdata(combined)\n",
    "        normal_scores = norm.ppf(ranks / (len(combined) + 1))\n",
    "    \n",
    "        scores1, scores2 = normal_scores[:size], normal_scores[size:]\n",
    "        mean_diff = np.abs(np.mean(scores1) - np.mean(scores2))\n",
    "        pooled_std = np.sqrt(np.var(scores1, ddof=1) / size + np.var(scores2, ddof=1) / size)\n",
    "        stat_waerden = mean_diff / pooled_std\n",
    "        p_value_waerden = 2 * (1 - norm.cdf(stat_waerden))\n",
    "        \n",
    "        # _, median_p_value = median_test(sample1, sample2)\n",
    "\n",
    "        # _, fy_p_value = fisher_yates_terry_hoeffding_test(sample1, sample2)\n",
    "\n",
    "        # perm_p_value, _ = permutation_test(sample1, sample2, alternative='two-sided')\n",
    "\n",
    "        # _, tstt_p_value = two_sample_t_test(sample1, sample2, equal_var=std_dev1==std_dev2, alternative='two-sided')\n",
    "\n",
    "        mw_p_values.append(p_value_mw)\n",
    "        waerden_p_values.append(p_value_waerden)\n",
    "        # median_test_p_values.append(median_p_value)\n",
    "        # fy_p_values.append(fy_p_value)\n",
    "        # perm_p_values.append(perm_p_value)\n",
    "        # tstt_p_values.append(tstt_p_value)\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 6))\n",
    "\n",
    "    # First subplot: Histograms of samples\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.hist(sample1, bins='auto', alpha=0.7, label=f'Sample 1 (Mean={mean1})', color='blue', edgecolor='black')\n",
    "    ax1.hist(sample2, bins='auto', alpha=0.7, label=f'Sample 2 (Mean={mean2})', color='orange', edgecolor='black')\n",
    "    ax1.axvline(np.mean(sample1), color='blue', linestyle='dashed', linewidth=1)\n",
    "    ax1.axvline(np.mean(sample2), color='orange', linestyle='dashed', linewidth=1)\n",
    "    \n",
    "    ax1.set_title(\"Histogram of Sample 1 and Sample 2\")\n",
    "    ax1.set_xlabel(\"Value\")\n",
    "    ax1.set_ylabel(\"Frequency\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Add text boxes\n",
    "    ax1.text(0.05, 0.95, f\"Mann-Whitney Test\\nStatistic: {stat_mw:.2f}\\nP-value: {p_value_mw:.4f}\\nSignificant: {p_value_mw < signif_alpha}\",\n",
    "             transform=ax1.transAxes, fontsize=10, verticalalignment='top', bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "    ax1.text(0.05, 0.75, f\"Van der Waerden Test\\nStatistic: {stat_waerden:.2f}\\nP-value: {p_value_waerden:.4f}\\nSignificant: {p_value_waerden < signif_alpha}\",\n",
    "             transform=ax1.transAxes, fontsize=10, verticalalignment='top', bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "\n",
    "    # Second subplot: Violin plots, box plots, and scatter overlay\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    data = [mw_p_values, waerden_p_values]\n",
    "    labels = ['Mann-Whitney', 'Waerden']\n",
    "    positions = [1, 2]\n",
    "    \n",
    "    # Violin plots\n",
    "    vp = ax2.violinplot(data, positions=positions, showmeans=False, showmedians=False, showextrema=False)\n",
    "    \n",
    "    # Customize violin plots\n",
    "    for i, pc in enumerate(vp['bodies']):\n",
    "        pc.set_alpha(0.5)\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_facecolor('lightblue')\n",
    "    \n",
    "    # Box plots\n",
    "    bp = ax2.boxplot(data, positions=positions, widths=0.1, patch_artist=True, \n",
    "                     boxprops=dict(facecolor='white', color='black'),\n",
    "                     medianprops=dict(color='black'),\n",
    "                     whiskerprops=dict(color='black'),\n",
    "                     capprops=dict(color='black'))\n",
    "    \n",
    "    # Overlay scatter plots\n",
    "    colors = ['red', 'red']\n",
    "    for i in range(len(data)):\n",
    "        y = data[i]\n",
    "        x = np.random.normal(positions[i], 0.05, size=len(y))\n",
    "        ax2.plot(x, y, '.', color=colors[i], alpha=0.5)\n",
    "    \n",
    "    # Add significance line\n",
    "    ax2.axhline(y=signif_alpha, color='red', linestyle='--', label=f'Alpha = {signif_alpha}')\n",
    "    ax2.text(0.05, 0.75, f\"MW Proportion: {len([i for i in mw_p_values if i < signif_alpha])/len(mw_p_values)}\",\n",
    "             transform=ax2.transAxes, fontsize=10, verticalalignment='top', bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "    ax2.text(0.05, 0.95, f\"Waerden Proportion: {len([i for i in waerden_p_values if i < signif_alpha])/len(waerden_p_values)}\",\n",
    "             transform=ax2.transAxes, fontsize=10, verticalalignment='top', bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "\n",
    "    # Set labels and title\n",
    "    ax2.set_xticks(positions)\n",
    "    ax2.set_xticklabels(labels)\n",
    "    ax2.set_title(\"P-values with Violin and Box Plots\")\n",
    "    ax2.set_ylabel(\"P-value\")\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_interactive_tests, \n",
    "         mean1=widgets.FloatSlider(value=50, min=0, max=100, step=1, description='Mean 1'),\n",
    "         delta=widgets.FloatSlider(value=0, min=-100, max=100, step=1, description='Delta'),\n",
    "         std_dev1=widgets.FloatSlider(value=10, min=1, max=30, step=1, description='Std Dev 1'),\n",
    "         std_dev2=widgets.FloatSlider(value=10, min=1, max=30, step=1, description='Std Dev 2'),\n",
    "         size=widgets.IntSlider(value=50, min=10, max=200, step=5, description='Sample Size'),\n",
    "         runs=widgets.IntSlider(value=10, min=10, max=200, step=10, description='Runs'),\n",
    "         signif_alpha=widgets.FloatSlider(value=0.05, min=0, max=1, step=0.01, description='Alpha'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d1c9315-7fc2-41b1-abd4-4ab4cedc1d3d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3cd84deeac475d9731bc9ab9d5adc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=50.0, description='Mean 1', step=1.0), FloatSlider(value=0.0, descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_interactive_tests(mean1=50, delta=0, std_dev1=10, std_dev2=10, size=100, signif_alpha=0.05, runs=100)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_interactive_tests(mean1=50, delta=0, std_dev1=10, std_dev2=10, size=100, signif_alpha=0.05, runs=100):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    mean2 = mean1 + delta\n",
    "    mw_p_values, waerden_p_values, median_test_p_values = [], [], []\n",
    "    fy_p_values, perm_p_values, tstt_p_values = [], [], []\n",
    "    \n",
    "    for _ in range(runs):\n",
    "        sample1 = np.random.normal(loc=mean1, scale=std_dev1, size=size)\n",
    "        sample2 = np.random.normal(loc=mean2, scale=std_dev2, size=size)\n",
    "    \n",
    "        stat_mw, p_value_mw = mannwhitneyu(sample1, sample2, alternative='two-sided')\n",
    "        combined = np.concatenate([sample1, sample2])\n",
    "        ranks = rankdata(combined)\n",
    "        normal_scores = norm.ppf(ranks / (len(combined) + 1))\n",
    "    \n",
    "        scores1, scores2 = normal_scores[:size], normal_scores[size:]\n",
    "        mean_diff = np.abs(np.mean(scores1) - np.mean(scores2))\n",
    "        pooled_std = np.sqrt(np.var(scores1, ddof=1) / size + np.var(scores2, ddof=1) / size)\n",
    "        stat_waerden = mean_diff / pooled_std\n",
    "        p_value_waerden = 2 * (1 - norm.cdf(stat_waerden))\n",
    "        \n",
    "        _, median_p_value = median_test(sample1, sample2)\n",
    "        _, fy_p_value = fisher_yates_terry_hoeffding_test(sample1, sample2)\n",
    "        perm_p_value, _ = permutation_test(sample1, sample2, alternative='two-sided')\n",
    "        _, tstt_p_value = two_sample_t_test(sample1, sample2, equal_var=std_dev1 == std_dev2, alternative='two-sided')\n",
    "\n",
    "        mw_p_values.append(p_value_mw)\n",
    "        waerden_p_values.append(p_value_waerden)\n",
    "        median_test_p_values.append(median_p_value)\n",
    "        fy_p_values.append(fy_p_value)\n",
    "        perm_p_values.append(perm_p_value)\n",
    "        tstt_p_values.append(tstt_p_value)\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 6))\n",
    "\n",
    "    # First subplot: Histograms of samples\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.hist(sample1, bins='auto', alpha=0.7, label=f'Sample 1 (Mean={mean1:.3f})', color='blue', edgecolor='black')\n",
    "    ax1.hist(sample2, bins='auto', alpha=0.7, label=f'Sample 2 (Mean={mean2:.3f})', color='orange', edgecolor='black')\n",
    "    ax1.axvline(np.mean(sample1), color='blue', linestyle='dashed', linewidth=1)\n",
    "    ax1.axvline(np.mean(sample2), color='orange', linestyle='dashed', linewidth=1)\n",
    "    ax1.set_title(\"Histogram of Sample 1 and Sample 2\")\n",
    "    ax1.set_xlabel(\"Value\")\n",
    "    ax1.set_ylabel(\"Frequency\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Add text boxes\n",
    "    ax1.text(0.05, 0.95, f\"Mann-Whitney Test\\nStatistic: {stat_mw:.2f}\\nP-value: {p_value_mw:.4f}\\nSignificant: {p_value_mw < signif_alpha}\",\n",
    "             transform=ax1.transAxes, fontsize=10, verticalalignment='top', bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "    ax1.text(0.05, 0.75, f\"Van der Waerden Test\\nStatistic: {stat_waerden:.2f}\\nP-value: {p_value_waerden:.4f}\\nSignificant: {p_value_waerden < signif_alpha}\",\n",
    "             transform=ax1.transAxes, fontsize=10, verticalalignment='top', bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "\n",
    "    # Second subplot: Violin plots, box plots, and scatter overlay\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    data = [mw_p_values, waerden_p_values, median_test_p_values, fy_p_values, perm_p_values, tstt_p_values]\n",
    "    labels = ['Mann-Whitney', 'Waerden', 'Median Test', 'FYTH', 'Permutation Test', 'Two-Sample T-Test']\n",
    "    positions = list(range(1, len(labels) + 1))\n",
    "    \n",
    "    # Violin plots\n",
    "    vp = ax2.violinplot(data, positions=positions, showmeans=False, showmedians=False, showextrema=False)\n",
    "    \n",
    "    # Customize violin plots\n",
    "    for i, pc in enumerate(vp['bodies']):\n",
    "        pc.set_alpha(0.5)\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_facecolor('lightblue')\n",
    "    \n",
    "    # Box plots\n",
    "    bp = ax2.boxplot(data, positions=positions, widths=0.1, patch_artist=True, \n",
    "                     boxprops=dict(facecolor='white', color='black'),\n",
    "                     medianprops=dict(color='black'),\n",
    "                     whiskerprops=dict(color='black'),\n",
    "                     capprops=dict(color='black'))\n",
    "    \n",
    "    # Overlay scatter plots\n",
    "    colors = ['red'] * len(data)\n",
    "    for i, y in enumerate(data):\n",
    "        x = np.random.normal(positions[i], 0.05, size=len(y))\n",
    "        ax2.plot(x, y, '.', color=colors[i], alpha=0.5)\n",
    "    \n",
    "    # Add significance line\n",
    "    ax2.axhline(y=signif_alpha, color='red', linestyle='--', label=f'Alpha = {signif_alpha}')\n",
    "\n",
    "    # Set labels and title\n",
    "    ax2.set_xticks(positions)\n",
    "    ax2.set_xticklabels(labels)\n",
    "    ax2.set_title(\"P-values with Violin and Box Plots\")\n",
    "    ax2.set_ylabel(\"P-value\")\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_interactive_tests, \n",
    "         mean1=widgets.FloatSlider(value=50, min=0, max=100, step=1, description='Mean 1'),\n",
    "         delta=widgets.FloatSlider(value=0, min=-50, max=50, step=1, description='Delta'),\n",
    "         std_dev1=widgets.FloatSlider(value=10, min=1, max=30, step=1, description='Std Dev 1'),\n",
    "         std_dev2=widgets.FloatSlider(value=10, min=1, max=30, step=1, description='Std Dev 2'),\n",
    "         size=widgets.IntSlider(value=50, min=10, max=200, step=5, description='Sample Size'),\n",
    "         runs=widgets.IntSlider(value=10, min=10, max=200, step=10, description='Runs'),\n",
    "         signif_alpha=widgets.FloatSlider(value=0.05, min=0, max=1, step=0.01, description='Alpha'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f19ce604-3526-46cc-955b-2d11946e2f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0794a4e1dc17425a9958c14447ecd698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=50.0, description='Mean 1', step=1.0), FloatSlider(value=0.0, descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_interactive_tests(mean1=50, delta=0, std_dev1=10, std_dev2=10, size=100, signif_alpha=0.05, runs=100, mw_test=True, waerden_test=True, median_t=True, fy_test=True, perm_test=True, t_test=True)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_interactive_tests(mean1=50, delta=0, std_dev1=10, std_dev2=10, size=100, signif_alpha=0.05, runs=100,\n",
    "                           mw_test=True, waerden_test=True, median_t=True, fy_test=True, perm_test=True, t_test=True):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy.stats import mannwhitneyu, rankdata, norm, median_test, ttest_ind\n",
    "    import ipywidgets as widgets\n",
    "\n",
    "    np.random.seed(42)\n",
    "    mean2 = mean1 + delta\n",
    "\n",
    "    # Initialize p-value lists\n",
    "    mw_p_values = []\n",
    "    waerden_p_values = []\n",
    "    median_test_p_values = []\n",
    "    fy_p_values = []\n",
    "    perm_p_values = []\n",
    "    tstt_p_values = []\n",
    "\n",
    "    for _ in range(runs):\n",
    "        sample1 = np.random.normal(loc=mean1, scale=std_dev1, size=size)\n",
    "        sample2 = np.random.normal(loc=mean2, scale=std_dev2, size=size)\n",
    "\n",
    "        if mw_test:\n",
    "            stat_mw, p_value_mw = mannwhitneyu(sample1, sample2, alternative='two-sided')\n",
    "            mw_p_values.append(p_value_mw)\n",
    "\n",
    "        if waerden_test:\n",
    "            combined = np.concatenate([sample1, sample2])\n",
    "            ranks = rankdata(combined)\n",
    "            normal_scores = norm.ppf(ranks / (len(combined) + 1))\n",
    "\n",
    "            scores1, scores2 = normal_scores[:size], normal_scores[size:]\n",
    "            mean_diff = np.abs(np.mean(scores1) - np.mean(scores2))\n",
    "            pooled_std = np.sqrt(np.var(scores1, ddof=1) / size + np.var(scores2, ddof=1) / size)\n",
    "            stat_waerden = mean_diff / pooled_std\n",
    "            p_value_waerden = 2 * (1 - norm.cdf(stat_waerden))\n",
    "            waerden_p_values.append(p_value_waerden)\n",
    "\n",
    "        if median_t:\n",
    "            _, median_p_value, _, _ = median_test(sample1, sample2)\n",
    "            median_test_p_values.append(median_p_value)\n",
    "\n",
    "        if fy_test:\n",
    "            # Placeholder for the FYTH test; replace with actual implementation\n",
    "            fy_p_value = np.random.rand()\n",
    "            fy_p_values.append(fy_p_value)\n",
    "\n",
    "        if perm_test:\n",
    "            # Placeholder for the permutation test; replace with actual implementation\n",
    "            perm_p_value = np.random.rand()\n",
    "            perm_p_values.append(perm_p_value)\n",
    "\n",
    "        if t_test:\n",
    "            _, tstt_p_value = ttest_ind(sample1, sample2, equal_var=std_dev1 == std_dev2)\n",
    "            tstt_p_values.append(tstt_p_value)\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 6))\n",
    "\n",
    "    # First subplot: Histograms of samples\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.hist(sample1, bins='auto', alpha=0.7, label=f'Sample 1 (Mean={mean1:.3f})', color='blue', edgecolor='black')\n",
    "    ax1.hist(sample2, bins='auto', alpha=0.7, label=f'Sample 2 (Mean={mean2:.3f})', color='orange', edgecolor='black')\n",
    "    ax1.axvline(np.mean(sample1), color='blue', linestyle='dashed', linewidth=1)\n",
    "    ax1.axvline(np.mean(sample2), color='orange', linestyle='dashed', linewidth=1)\n",
    "    ax1.set_title(\"Histogram of Sample 1 and Sample 2\")\n",
    "    ax1.set_xlabel(\"Value\")\n",
    "    ax1.set_ylabel(\"Frequency\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Prepare text boxes\n",
    "    text_boxes = []\n",
    "    if mw_test:\n",
    "        text_boxes.append((\"Mann-Whitney Test\", None, np.mean(mw_p_values), np.mean(mw_p_values) < signif_alpha))\n",
    "    if waerden_test:\n",
    "        text_boxes.append((\"Van der Waerden Test\", None, np.mean(waerden_p_values), np.mean(waerden_p_values) < signif_alpha))\n",
    "    if median_t:\n",
    "        text_boxes.append((\"Median Test\", None, np.mean(median_test_p_values), np.mean(median_test_p_values) < signif_alpha))\n",
    "    if fy_test:\n",
    "        text_boxes.append((\"FYTH Test\", None, np.mean(fy_p_values), np.mean(fy_p_values) < signif_alpha))\n",
    "    if perm_test:\n",
    "        text_boxes.append((\"Permutation Test\", None, np.mean(perm_p_values), np.mean(perm_p_values) < signif_alpha))\n",
    "    if t_test:\n",
    "        text_boxes.append((\"Two-Sample T-Test\", None, np.mean(tstt_p_values), np.mean(tstt_p_values) < signif_alpha))\n",
    "\n",
    "    # Display text boxes\n",
    "    if text_boxes:\n",
    "        vstep = 0.15\n",
    "        vpos = 0.95\n",
    "        for test_name, stat, p_value, significant in text_boxes:\n",
    "            text = f\"{test_name}\\nMean P-value: {p_value:.4f}\\nSignificant: {significant}\"\n",
    "            ax1.text(0.05, vpos, text,\n",
    "                     transform=ax1.transAxes, fontsize=10, verticalalignment='top',\n",
    "                     bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "            vpos -= vstep\n",
    "\n",
    "    # Second subplot: Violin plots, box plots, and scatter overlay\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    data = []\n",
    "    labels = []\n",
    "    positions = []\n",
    "    position_counter = 1\n",
    "\n",
    "    if mw_test:\n",
    "        data.append(mw_p_values)\n",
    "        labels.append('Mann-Whitney')\n",
    "        positions.append(position_counter)\n",
    "        position_counter += 1\n",
    "\n",
    "    if waerden_test:\n",
    "        data.append(waerden_p_values)\n",
    "        labels.append('Waerden')\n",
    "        positions.append(position_counter)\n",
    "        position_counter += 1\n",
    "\n",
    "    if median_t:\n",
    "        data.append(median_test_p_values)\n",
    "        labels.append('Median Test')\n",
    "        positions.append(position_counter)\n",
    "        position_counter += 1\n",
    "\n",
    "    if fy_test:\n",
    "        data.append(fy_p_values)\n",
    "        labels.append('FYTH')\n",
    "        positions.append(position_counter)\n",
    "        position_counter += 1\n",
    "\n",
    "    if perm_test:\n",
    "        data.append(perm_p_values)\n",
    "        labels.append('Permutation Test')\n",
    "        positions.append(position_counter)\n",
    "        position_counter += 1\n",
    "\n",
    "    if t_test:\n",
    "        data.append(tstt_p_values)\n",
    "        labels.append('Two-Sample T-Test')\n",
    "        positions.append(position_counter)\n",
    "        position_counter += 1\n",
    "\n",
    "    if data:\n",
    "        # Violin plots\n",
    "        vp = ax2.violinplot(data, positions=positions, showmeans=False, showmedians=False, showextrema=False)\n",
    "\n",
    "        # Customize violin plots\n",
    "        for pc in vp['bodies']:\n",
    "            pc.set_alpha(0.5)\n",
    "            pc.set_edgecolor('black')\n",
    "            pc.set_facecolor('lightblue')\n",
    "\n",
    "        # Box plots\n",
    "        bp = ax2.boxplot(data, positions=positions, widths=0.1, patch_artist=True,\n",
    "                         boxprops=dict(facecolor='white', color='black'),\n",
    "                         medianprops=dict(color='black'),\n",
    "                         whiskerprops=dict(color='black'),\n",
    "                         capprops=dict(color='black'))\n",
    "\n",
    "        # Overlay scatter plots\n",
    "        colors = ['red'] * len(data)\n",
    "        for i, y in enumerate(data):\n",
    "            x = np.random.normal(positions[i], 0.05, size=len(y))\n",
    "            ax2.plot(x, y, '.', color=colors[i], alpha=0.5)\n",
    "\n",
    "        # Add significance line\n",
    "        ax2.axhline(y=signif_alpha, color='red', linestyle='--', label=f'Alpha = {signif_alpha}')\n",
    "\n",
    "        # Set labels and title\n",
    "        ax2.set_xticks(positions)\n",
    "        ax2.set_xticklabels(labels, rotation=45)\n",
    "        ax2.set_title(\"P-values with Violin and Box Plots\")\n",
    "        ax2.set_ylabel(\"P-value\")\n",
    "        ax2.legend()\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'No tests selected.', transform=ax2.transAxes,\n",
    "                 fontsize=14, ha='center', va='center')\n",
    "        ax2.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "interact(plot_interactive_tests, \n",
    "         mean1=widgets.FloatSlider(value=50, min=0, max=100, step=1, description='Mean 1'),\n",
    "         delta=widgets.FloatSlider(value=0, min=-50, max=50, step=1, description='Delta'),\n",
    "         std_dev1=widgets.FloatSlider(value=10, min=1, max=30, step=1, description='Std Dev 1'),\n",
    "         std_dev2=widgets.FloatSlider(value=10, min=1, max=30, step=1, description='Std Dev 2'),\n",
    "         size=widgets.IntSlider(value=50, min=10, max=200, step=5, description='Sample Size'),\n",
    "         runs=widgets.IntSlider(value=10, min=10, max=200, step=10, description='Runs'),\n",
    "         signif_alpha=widgets.FloatSlider(value=0.05, min=0, max=1, step=0.01, description='Alpha'),\n",
    "         mw_test=widgets.ToggleButton(value=True, description='Mann-Whitney'),\n",
    "         waerden_test=widgets.ToggleButton(value=True, description='Waerden'),\n",
    "         median_t=widgets.ToggleButton(value=True, description='Median Test'),\n",
    "         fy_test=widgets.ToggleButton(value=True, description='FYTH'),\n",
    "         perm_test=widgets.ToggleButton(value=True, description='Permutation Test'),\n",
    "         t_test=widgets.ToggleButton(value=True, description='Two-Sample T-Test'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4acba6c4-0120-41d2-9650-3bbab3846f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d5d0fb453d4604be3f24e3d75a3541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=50.0, description='Mean 1', step=1.0), FloatSlider(value=0.0, descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_interactive_tests(mean1=50, delta=0, std_dev1=10, std_dev2=10, size=100, signif_alpha=0.05, runs=100, mw_test=True, waerden_test=True, median_t=True, fy_test=True, perm_test=True, t_test=True)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_interactive_tests(mean1=50, delta=0, std_dev1=10, std_dev2=10, size=100, signif_alpha=0.05, runs=100,\n",
    "                           mw_test=True, waerden_test=True, median_t=True, fy_test=True, perm_test=True, t_test=True):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy.stats import mannwhitneyu, rankdata, norm, median_test, ttest_ind\n",
    "    import ipywidgets as widgets\n",
    "\n",
    "    np.random.seed(42)\n",
    "    mean2 = mean1 + delta\n",
    "\n",
    "    # Initialize p-value lists\n",
    "    mw_p_values = []\n",
    "    waerden_p_values = []\n",
    "    median_test_p_values = []\n",
    "    fy_p_values = []\n",
    "    perm_p_values = []\n",
    "    tstt_p_values = []\n",
    "\n",
    "    for _ in range(runs):\n",
    "        sample1 = np.random.normal(loc=mean1, scale=std_dev1, size=size)\n",
    "        sample2 = np.random.normal(loc=mean2, scale=std_dev2, size=size)\n",
    "\n",
    "        if mw_test:\n",
    "            stat_mw, p_value_mw = mannwhitneyu(sample1, sample2, alternative='two-sided')\n",
    "            mw_p_values.append(p_value_mw)\n",
    "\n",
    "        if waerden_test:\n",
    "            combined = np.concatenate([sample1, sample2])\n",
    "            ranks = rankdata(combined)\n",
    "            normal_scores = norm.ppf(ranks / (len(combined) + 1))\n",
    "\n",
    "            scores1, scores2 = normal_scores[:size], normal_scores[size:]\n",
    "            mean_diff = np.abs(np.mean(scores1) - np.mean(scores2))\n",
    "            pooled_std = np.sqrt(np.var(scores1, ddof=1) / size + np.var(scores2, ddof=1) / size)\n",
    "            stat_waerden = mean_diff / pooled_std\n",
    "            p_value_waerden = 2 * (1 - norm.cdf(stat_waerden))\n",
    "            waerden_p_values.append(p_value_waerden)\n",
    "\n",
    "        if median_t:\n",
    "            _, median_p_value, _, _ = median_test(sample1, sample2)\n",
    "            median_test_p_values.append(median_p_value)\n",
    "\n",
    "        if fy_test:\n",
    "            # Placeholder for the FYTH test; replace with actual implementation\n",
    "            fy_p_value = np.random.rand()\n",
    "            fy_p_values.append(fy_p_value)\n",
    "\n",
    "        if perm_test:\n",
    "            # Placeholder for the permutation test; replace with actual implementation\n",
    "            perm_p_value = np.random.rand()\n",
    "            perm_p_values.append(perm_p_value)\n",
    "\n",
    "        if t_test:\n",
    "            _, tstt_p_value = ttest_ind(sample1, sample2, equal_var=std_dev1 == std_dev2)\n",
    "            tstt_p_values.append(tstt_p_value)\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 6))\n",
    "\n",
    "    # First subplot: Histograms of samples\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.hist(sample1, bins='auto', alpha=0.7, label=f'Sample 1 (Mean={mean1:.3f})', color='blue', edgecolor='black')\n",
    "    ax1.hist(sample2, bins='auto', alpha=0.7, label=f'Sample 2 (Mean={mean2:.3f})', color='orange', edgecolor='black')\n",
    "    ax1.axvline(np.mean(sample1), color='blue', linestyle='dashed', linewidth=1)\n",
    "    ax1.axvline(np.mean(sample2), color='orange', linestyle='dashed', linewidth=1)\n",
    "    ax1.set_title(\"Histogram of Sample 1 and Sample 2\")\n",
    "    ax1.set_xlabel(\"Value\")\n",
    "    ax1.set_ylabel(\"Frequency\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Prepare text boxes\n",
    "    # text_boxes = []\n",
    "    # if mw_test:\n",
    "    #     text_boxes.append((\"Mann-Whitney Test\", None, np.mean(mw_p_values), np.mean(mw_p_values) < signif_alpha))\n",
    "    # if waerden_test:\n",
    "    #     text_boxes.append((\"Van der Waerden Test\", None, np.mean(waerden_p_values), np.mean(waerden_p_values) < signif_alpha))\n",
    "    # if median_t:\n",
    "    #     text_boxes.append((\"Median Test\", None, np.mean(median_test_p_values), np.mean(median_test_p_values) < signif_alpha))\n",
    "    # if fy_test:\n",
    "    #     text_boxes.append((\"FYTH Test\", None, np.mean(fy_p_values), np.mean(fy_p_values) < signif_alpha))\n",
    "    # if perm_test:\n",
    "    #     text_boxes.append((\"Permutation Test\", None, np.mean(perm_p_values), np.mean(perm_p_values) < signif_alpha))\n",
    "    # if t_test:\n",
    "    #     text_boxes.append((\"Two-Sample T-Test\", None, np.mean(tstt_p_values), np.mean(tstt_p_values) < signif_alpha))\n",
    "\n",
    "    # # Display text boxes\n",
    "    # if text_boxes:\n",
    "    #     vstep = 0.15\n",
    "    #     vpos = 0.95\n",
    "    #     for test_name, stat, p_value, significant in text_boxes:\n",
    "    #         text = f\"{test_name}\\nMean P-value: {p_value:.4f}\\nSignificant: {significant}\"\n",
    "    #         ax1.text(0.05, vpos, text,\n",
    "    #                  transform=ax1.transAxes, fontsize=10, verticalalignment='top',\n",
    "    #                  bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "    #         vpos -= vstep\n",
    "\n",
    "    # Second subplot: Violin plots, box plots, and scatter overlay\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    data = []\n",
    "    labels = []\n",
    "    positions = []\n",
    "    proportions = []\n",
    "    position_counter = 1\n",
    "\n",
    "    if mw_test:\n",
    "        data.append(mw_p_values)\n",
    "        labels.append('Mann-Whitney')\n",
    "        positions.append(position_counter)\n",
    "        prop_mw = len([i for i in mw_p_values if i < signif_alpha]) / len(mw_p_values)\n",
    "        proportions.append(prop_mw)\n",
    "        position_counter += 1\n",
    "\n",
    "    if waerden_test:\n",
    "        data.append(waerden_p_values)\n",
    "        labels.append('Waerden')\n",
    "        positions.append(position_counter)\n",
    "        prop_waerden = len([i for i in waerden_p_values if i < signif_alpha]) / len(waerden_p_values)\n",
    "        proportions.append(prop_waerden)\n",
    "        position_counter += 1\n",
    "\n",
    "    if median_t:\n",
    "        data.append(median_test_p_values)\n",
    "        labels.append('Median Test')\n",
    "        positions.append(position_counter)\n",
    "        prop_median = len([i for i in median_test_p_values if i < signif_alpha]) / len(median_test_p_values)\n",
    "        proportions.append(prop_median)\n",
    "        position_counter += 1\n",
    "\n",
    "    if fy_test:\n",
    "        data.append(fy_p_values)\n",
    "        labels.append('FYTH')\n",
    "        positions.append(position_counter)\n",
    "        prop_fyth = len([i for i in fy_p_values if i < signif_alpha]) / len(fy_p_values)\n",
    "        proportions.append(prop_fyth)\n",
    "        position_counter += 1\n",
    "\n",
    "    if perm_test:\n",
    "        data.append(perm_p_values)\n",
    "        labels.append('Permutation Test')\n",
    "        positions.append(position_counter)\n",
    "        prop_perm = len([i for i in perm_p_values if i < signif_alpha]) / len(perm_p_values)\n",
    "        proportions.append(prop_perm)\n",
    "        position_counter += 1\n",
    "\n",
    "    if t_test:\n",
    "        data.append(tstt_p_values)\n",
    "        labels.append('Two-Sample T-Test')\n",
    "        positions.append(position_counter)\n",
    "        prop_ttest = len([i for i in tstt_p_values if i < signif_alpha]) / len(tstt_p_values)\n",
    "        proportions.append(prop_ttest)\n",
    "        position_counter += 1\n",
    "\n",
    "    if data:\n",
    "        # Violin plots\n",
    "        vp = ax2.violinplot(data, positions=positions, showmeans=False, showmedians=False, showextrema=False)\n",
    "\n",
    "        # Customize violin plots\n",
    "        for pc in vp['bodies']:\n",
    "            pc.set_alpha(0.5)\n",
    "            pc.set_edgecolor('black')\n",
    "            pc.set_facecolor('lightblue')\n",
    "\n",
    "        # Box plots\n",
    "        bp = ax2.boxplot(data, positions=positions, widths=0.1, patch_artist=True,\n",
    "                         boxprops=dict(facecolor='white', color='black'),\n",
    "                         medianprops=dict(color='black'),\n",
    "                         whiskerprops=dict(color='black'),\n",
    "                         capprops=dict(color='black'))\n",
    "\n",
    "        # Overlay scatter plots\n",
    "        colors = ['red'] * len(data)\n",
    "        for i, y in enumerate(data):\n",
    "            x = np.random.normal(positions[i], 0.05, size=len(y))\n",
    "            ax2.plot(x, y, '.', color=colors[i], alpha=0.5)\n",
    "\n",
    "        # Add significance line\n",
    "        ax2.axhline(y=signif_alpha, color='red', linestyle='--', label=f'Alpha = {signif_alpha}')\n",
    "\n",
    "        # Include proportions in x-axis labels\n",
    "        labels_with_prop = [f\"{label}\\nProp: {prop:.2%}\" for label, prop in zip(labels, proportions)]\n",
    "\n",
    "        # Set labels and title\n",
    "        ax2.set_xticks(positions)\n",
    "        ax2.set_xticklabels(labels_with_prop, rotation=45)\n",
    "        ax2.set_title(\"P-values with Violin and Box Plots\")\n",
    "        ax2.set_ylabel(\"P-value\")\n",
    "        ax2.legend()\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'No tests selected.', transform=ax2.transAxes,\n",
    "                 fontsize=14, ha='center', va='center')\n",
    "        ax2.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "interact(plot_interactive_tests, \n",
    "         mean1=widgets.FloatSlider(value=50, min=0, max=100, step=1, description='Mean 1'),\n",
    "         delta=widgets.FloatSlider(value=0, min=-50, max=50, step=1, description='Delta'),\n",
    "         std_dev1=widgets.FloatSlider(value=10, min=1, max=30, step=1, description='Std Dev 1'),\n",
    "         std_dev2=widgets.FloatSlider(value=10, min=1, max=30, step=1, description='Std Dev 2'),\n",
    "         size=widgets.IntSlider(value=50, min=10, max=200, step=5, description='Sample Size'),\n",
    "         runs=widgets.IntSlider(value=10, min=10, max=200, step=10, description='Runs'),\n",
    "         signif_alpha=widgets.FloatSlider(value=0.05, min=0, max=1, step=0.01, description='Alpha'),\n",
    "         mw_test=widgets.ToggleButton(value=True, description='Mann-Whitney'),\n",
    "         waerden_test=widgets.ToggleButton(value=True, description='Waerden'),\n",
    "         median_t=widgets.ToggleButton(value=True, description='Median Test'),\n",
    "         fy_test=widgets.ToggleButton(value=True, description='FYTH'),\n",
    "         perm_test=widgets.ToggleButton(value=True, description='Permutation Test'),\n",
    "         t_test=widgets.ToggleButton(value=True, description='Two-Sample T-Test'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdff42a-e839-4d2f-998a-b7f227e5b072",
   "metadata": {},
   "source": [
    "### book page 970"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07cab15-89ad-4a8b-94fc-29b0fa39c21b",
   "metadata": {},
   "source": [
    "# Poisson distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6dd93e40-d554-4b71-818c-4e1a8bc0207c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e507876e0c7e453ca65721334ffad206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='Mean 1', max=10.0, min=-10.0), FloatSlider(value=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_interactive_tests(mean1=0, mean2=0, size=100)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_interactive_tests(mean1=0, mean2=0, size=100):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    mean1 = 10 ** mean1\n",
    "    mean2 = 10 ** mean2\n",
    "    \n",
    "    sample1 = np.random.poisson(lam=mean1, size=size)\n",
    "    sample2 = np.random.poisson(lam=mean2, size=size)\n",
    "\n",
    "    stat_mw, p_value_mw = mannwhitneyu(sample1, sample2, alternative='two-sided')\n",
    "    \n",
    "    combined = np.concatenate([sample1, sample2])\n",
    "    ranks = rankdata(combined)\n",
    "    normal_scores = norm.ppf(ranks / (len(combined) + 1))\n",
    "\n",
    "    scores1, scores2 = normal_scores[:size], normal_scores[size:]\n",
    "    mean_diff = np.abs(np.mean(scores1) - np.mean(scores2))\n",
    "    pooled_std = np.sqrt(np.var(scores1, ddof=1) / size + np.var(scores2, ddof=1) / size)\n",
    "    stat_waerden = mean_diff / pooled_std\n",
    "    p_value_waerden = 2 * (1 - norm.cdf(stat_waerden))\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(sample1, bins='auto', alpha=0.7, label=f'Sample 1 (Mean={mean1:.3f})', color='blue', edgecolor='black')\n",
    "    plt.hist(sample2, bins='auto', alpha=0.7, label=f'Sample 2 (Mean={mean2:.3f})', color='orange', edgecolor='black')\n",
    "    plt.axvline(np.mean(sample1), color='blue', linestyle='dashed', linewidth=1)\n",
    "    plt.axvline(np.mean(sample2), color='orange', linestyle='dashed', linewidth=1)\n",
    "    plt.title(\"Histogram of Sample 1 and Sample 2\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figtext(0.15, 0.75, f\"Wilcoxon Mann-Whitney Test\\nStatistic: {stat_mw:.2f}\\nP-value: {p_value_mw:.4f}\", \n",
    "                fontsize=10, color=\"black\", bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "    plt.figtext(0.15, 0.65, f\"Van der Waerden Test\\nStatistic: {stat_waerden:.2f}\\nP-value: {p_value_waerden:.4f}\", \n",
    "                fontsize=10, color=\"black\", bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_interactive_tests, \n",
    "         mean1=widgets.FloatSlider(value=0, min=-10, max=10, step=0.1, description='Mean 1'),\n",
    "         mean2=widgets.FloatSlider(value=0, min=-10, max=10, step=0.1, description='Mean 2'),\n",
    "         size=widgets.IntSlider(value=300, min=100, max=500, step=50, description='Sample Size')\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3024463-630f-48a7-8048-811298dca3c8",
   "metadata": {},
   "source": [
    "# Mixture distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "404635ac-ffe3-45ed-9da1-15e117d138ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69.12391219 39.85690732 68.76124807 84.4227826  54.06424988 67.12086703\n",
      " 53.47270586 53.43230581 52.23069044 91.05931255]\n"
     ]
    }
   ],
   "source": [
    "def generate_mixture_samples(mean1, std_dev1, mean2, std_dev2, size, threshold=0.5):\n",
    "    # Generate samples from both distributions\n",
    "    sample1 = np.random.normal(loc=mean1, scale=std_dev1, size=size)\n",
    "    sample2 = np.random.normal(loc=mean2, scale=std_dev2, size=size)\n",
    "\n",
    "    # Generate random probabilities to determine which distribution to choose\n",
    "    random_probs = np.random.uniform(0, 1, size)\n",
    "\n",
    "    # Choose samples based on the threshold\n",
    "    samples = np.where(random_probs > threshold, sample1, sample2)\n",
    "\n",
    "    return samples\n",
    "\n",
    "# Example usage:\n",
    "mean1, std_dev1 = 50, 10\n",
    "mean2, std_dev2 = 70, 15\n",
    "size = 10\n",
    "prob = 0.7\n",
    "threshold = 0.5\n",
    "\n",
    "mixture_samples = generate_mixture_samples(mean1, std_dev1, mean2, std_dev2, size, threshold)\n",
    "print(mixture_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a83fdc8-7da2-402d-b22a-2fe6de96f844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561c912827b9494f9b40dda55027f275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=50.0, description='Mean 1', step=1.0), FloatSlider(value=0.0, descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_interactive_tests_mixture(mean1=50, delta=0, std_dev1=10, std_dev2=10, size=100, signif_alpha=0.05, runs=100, mixture_thresh=0.1)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_interactive_tests_mixture(\n",
    "    mean1=50, delta=0, std_dev1=10, std_dev2=10, size=100, signif_alpha=0.05, \n",
    "    runs=100, mixture_thresh=0.1):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    mean2 = mean1 + delta\n",
    "    mw_p_values, waerden_p_values, median_test_p_values = [], [], []\n",
    "    fy_p_values, perm_p_values, tstt_p_values = [], [], []\n",
    "    \n",
    "    for _ in range(runs):\n",
    "        sample1 = generate_mixture_samples(mean1, std_dev1, mean1 + 3*std_dev1, std_dev1*0.1, size, mixture_thresh)\n",
    "        sample2 = generate_mixture_samples(mean2, std_dev2, mean2 + 3*std_dev2, std_dev2*0.1, size, mixture_thresh)\n",
    "    \n",
    "        stat_mw, p_value_mw = mannwhitneyu(sample1, sample2, alternative='two-sided')\n",
    "        combined = np.concatenate([sample1, sample2])\n",
    "        ranks = rankdata(combined)\n",
    "        normal_scores = norm.ppf(ranks / (len(combined) + 1))\n",
    "    \n",
    "        scores1, scores2 = normal_scores[:size], normal_scores[size:]\n",
    "        mean_diff = np.abs(np.mean(scores1) - np.mean(scores2))\n",
    "        pooled_std = np.sqrt(np.var(scores1, ddof=1) / size + np.var(scores2, ddof=1) / size)\n",
    "        stat_waerden = mean_diff / pooled_std\n",
    "        p_value_waerden = 2 * (1 - norm.cdf(stat_waerden))\n",
    "        \n",
    "        # _, median_p_value = median_test(sample1, sample2)\n",
    "\n",
    "        # _, fy_p_value = fisher_yates_terry_hoeffding_test(sample1, sample2)\n",
    "\n",
    "        # perm_p_value, _ = permutation_test(sample1, sample2, alternative='two-sided')\n",
    "\n",
    "        # _, tstt_p_value = two_sample_t_test(sample1, sample2, equal_var=std_dev1==std_dev2, alternative='two-sided')\n",
    "\n",
    "        mw_p_values.append(p_value_mw)\n",
    "        waerden_p_values.append(p_value_waerden)\n",
    "        # median_test_p_values.append(median_p_value)\n",
    "        # fy_p_values.append(fy_p_value)\n",
    "        # perm_p_values.append(perm_p_value)\n",
    "        # tstt_p_values.append(tstt_p_value)\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 6))\n",
    "\n",
    "    # First subplot: Histograms of samples\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.hist(sample1, bins='auto', alpha=0.7, label=f'Sample 1 (Mean={mean1})', color='blue', edgecolor='black')\n",
    "    ax1.hist(sample2, bins='auto', alpha=0.7, label=f'Sample 2 (Mean={mean2})', color='orange', edgecolor='black')\n",
    "    ax1.axvline(np.mean(sample1), color='blue', linestyle='dashed', linewidth=1)\n",
    "    ax1.axvline(np.mean(sample2), color='orange', linestyle='dashed', linewidth=1)\n",
    "    \n",
    "    ax1.set_title(\"Histogram of Sample 1 and Sample 2\")\n",
    "    ax1.set_xlabel(\"Value\")\n",
    "    ax1.set_ylabel(\"Frequency\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Add text boxes\n",
    "    ax1.text(0.05, 0.95, f\"Mann-Whitney Test\\nStatistic: {stat_mw:.2f}\\nP-value: {p_value_mw:.4f}\\nSignificant: {p_value_mw < signif_alpha}\",\n",
    "             transform=ax1.transAxes, fontsize=10, verticalalignment='top', bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "    ax1.text(0.05, 0.75, f\"Van der Waerden Test\\nStatistic: {stat_waerden:.2f}\\nP-value: {p_value_waerden:.4f}\\nSignificant: {p_value_waerden < signif_alpha}\",\n",
    "             transform=ax1.transAxes, fontsize=10, verticalalignment='top', bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "\n",
    "    # Second subplot: Violin plots, box plots, and scatter overlay\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    data = [mw_p_values, waerden_p_values]\n",
    "    labels = ['Mann-Whitney', 'Waerden']\n",
    "    positions = [1, 2]\n",
    "    \n",
    "    # Violin plots\n",
    "    vp = ax2.violinplot(data, positions=positions, showmeans=False, showmedians=False, showextrema=False)\n",
    "    \n",
    "    # Customize violin plots\n",
    "    for i, pc in enumerate(vp['bodies']):\n",
    "        pc.set_alpha(0.5)\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_facecolor('lightblue')\n",
    "    \n",
    "    # Box plots\n",
    "    bp = ax2.boxplot(data, positions=positions, widths=0.1, patch_artist=True, \n",
    "                     boxprops=dict(facecolor='white', color='black'),\n",
    "                     medianprops=dict(color='black'),\n",
    "                     whiskerprops=dict(color='black'),\n",
    "                     capprops=dict(color='black'))\n",
    "    \n",
    "    # Overlay scatter plots\n",
    "    colors = ['red', 'red']\n",
    "    for i in range(len(data)):\n",
    "        y = data[i]\n",
    "        x = np.random.normal(positions[i], 0.05, size=len(y))\n",
    "        ax2.plot(x, y, '.', color=colors[i], alpha=0.5)\n",
    "    \n",
    "    # Add significance line\n",
    "    ax2.axhline(y=signif_alpha, color='red', linestyle='--', label=f'Alpha = {signif_alpha}')\n",
    "\n",
    "    # Set labels and title\n",
    "    ax2.set_xticks(positions)\n",
    "    ax2.set_xticklabels(labels)\n",
    "    ax2.set_title(\"P-values with Violin and Box Plots\")\n",
    "    ax2.set_ylabel(\"P-value\")\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_interactive_tests_mixture, \n",
    "         mean1=widgets.FloatSlider(value=50, min=0, max=100, step=1, description='Mean 1'),\n",
    "         delta=widgets.FloatSlider(value=0, min=-100, max=100, step=1, description='Delta'),\n",
    "         std_dev1=widgets.FloatSlider(value=10, min=1, max=30, step=1, description='Std Dev 1'),\n",
    "         std_dev2=widgets.FloatSlider(value=10, min=1, max=30, step=1, description='Std Dev 2'),\n",
    "         size=widgets.IntSlider(value=300, min=100, max=500, step=50, description='Sample Size'),\n",
    "         runs=widgets.IntSlider(value=100, min=100, max=500, step=50, description='Runs'),\n",
    "         signif_alpha=widgets.FloatSlider(value=0.05, min=0, max=1, step=0.01, description='Alpha'),\n",
    "         mixture_thresh=widgets.FloatSlider(value=0.1, min=0, max=1, step=0.1, description='Mixture percent'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983b7da6-5b7f-4a07-90eb-70d0507efb98",
   "metadata": {},
   "source": [
    "# T distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "775ddee3-84a8-4057-8b50-8353cf697791",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77e9a13513840dbae3f9c84938ae32b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=5.0, description='Mean 1', max=60.0, min=1.0), FloatSlider(value=10.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_interactive_tests(mean1=50, mean2=55, size=100, df=2)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_interactive_tests(mean1=50, mean2=55, size=100, df=2):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    sample1 = np.random.standard_t(df=df, size=size) * mean1 / 10 + mean1\n",
    "    sample2 = np.random.standard_t(df=df, size=size) * mean2 / 10 + mean2\n",
    "\n",
    "    stat_mw, p_value_mw = mannwhitneyu(sample1, sample2, alternative='two-sided')\n",
    "    \n",
    "    combined = np.concatenate([sample1, sample2])\n",
    "    ranks = rankdata(combined)\n",
    "    normal_scores = norm.ppf(ranks / (len(combined) + 1))\n",
    "\n",
    "    scores1, scores2 = normal_scores[:size], normal_scores[size:]\n",
    "    mean_diff = np.abs(np.mean(scores1) - np.mean(scores2))\n",
    "    pooled_std = np.sqrt(np.var(scores1, ddof=1) / size + np.var(scores2, ddof=1) / size)\n",
    "    stat_waerden = mean_diff / pooled_std\n",
    "    p_value_waerden = 2 * (1 - norm.cdf(stat_waerden))\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(sample1, bins='auto', alpha=0.7, label=f'Sample 1 (Mean={mean1})', color='blue', edgecolor='black')\n",
    "    plt.hist(sample2, bins='auto', alpha=0.7, label=f'Sample 2 (Mean={mean2})', color='orange', edgecolor='black')\n",
    "    plt.axvline(np.mean(sample1), color='blue', linestyle='dashed', linewidth=1)\n",
    "    plt.axvline(np.mean(sample2), color='orange', linestyle='dashed', linewidth=1)\n",
    "    plt.title(\"Histogram of Sample 1 and Sample 2\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figtext(0.15, 0.75, f\"Wilcoxon Mann-Whitney Test\\nStatistic: {stat_mw:.2f}\\nP-value: {p_value_mw:.4f}\", \n",
    "                fontsize=10, color=\"black\", bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "    plt.figtext(0.15, 0.65, f\"Van der Waerden Test\\nStatistic: {stat_waerden:.2f}\\nP-value: {p_value_waerden:.4f}\", \n",
    "                fontsize=10, color=\"black\", bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "    \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_interactive_tests, \n",
    "        mean1=widgets.FloatSlider(value=5, min=1, max=60, step=0.1, description='Mean 1'),\n",
    "        mean2=widgets.FloatSlider(value=10, min=1, max=60, step=0.1, description='Mean 2'),\n",
    "        size=widgets.IntSlider(value=300, min=100, max=500, step=50, description='Sample Size'),\n",
    "        df=widgets.IntSlider(value=20, min=1, max=50, step=1, description='Degree of freedom'),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd7f843-58f9-4d1c-ac6a-65cb356e1cf9",
   "metadata": {},
   "source": [
    "# Cauchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d30282b-e5b9-4440-b69e-b8167152bcaf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f03762b32343e8b02f4c56abb03230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='Loc 1', max=10.0, min=-10.0), FloatSlider(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_interactive_tests(loc1=0, scale1=1, loc2=0, scale2=1, size=100)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_interactive_tests(loc1=0, scale1=1, loc2=0, scale2=1, size=100):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    sample1 = cauchy.rvs(loc=loc1, scale=scale1, size=size)\n",
    "    sample2 = cauchy.rvs(loc=loc2, scale=scale2, size=size)\n",
    "\n",
    "    stat_mw, p_value_mw = mannwhitneyu(sample1, sample2, alternative='two-sided')\n",
    "    \n",
    "    combined = np.concatenate([sample1, sample2])\n",
    "    ranks = rankdata(combined)\n",
    "    normal_scores = norm.ppf(ranks / (len(combined) + 1))\n",
    "\n",
    "    scores1, scores2 = normal_scores[:size], normal_scores[size:]\n",
    "    mean_diff = np.abs(np.mean(scores1) - np.mean(scores2))\n",
    "    pooled_std = np.sqrt(np.var(scores1, ddof=1) / size + np.var(scores2, ddof=1) / size)\n",
    "    stat_waerden = mean_diff / pooled_std\n",
    "    p_value_waerden = 2 * (1 - norm.cdf(stat_waerden))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(sample1, bins='auto', alpha=0.7, label=f'Sample 1 (Loc={loc1}, Scale={scale1})', color='blue', edgecolor='black')\n",
    "    plt.hist(sample2, bins='auto', alpha=0.7, label=f'Sample 2 (Loc={loc2}, Scale={scale2})', color='orange', edgecolor='black')\n",
    "    plt.axvline(np.median(sample1), color='blue', linestyle='dashed', linewidth=1)\n",
    "    plt.axvline(np.median(sample2), color='orange', linestyle='dashed', linewidth=1)\n",
    "    plt.title(\"Histogram of Sample 1 and Sample 2\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figtext(0.15, 0.75, f\"Wilcoxon Mann-Whitney Test\\nStatistic: {stat_mw:.2f}\\nP-value: {p_value_mw:.4f}\", \n",
    "                fontsize=10, color=\"black\", bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "    plt.figtext(0.15, 0.65, f\"Van der Waerden Test\\nStatistic: {stat_waerden:.2f}\\nP-value: {p_value_waerden:.4f}\", \n",
    "                fontsize=10, color=\"black\", bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.5\"))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_interactive_tests, \n",
    "         loc1=widgets.FloatSlider(value=0, min=-10, max=10, step=0.1, description='Loc 1'),\n",
    "         scale1=widgets.FloatSlider(value=1, min=0.1, max=10, step=0.1, description='Scale 1'),\n",
    "         loc2=widgets.FloatSlider(value=0, min=-10, max=10, step=0.1, description='Loc 2'),\n",
    "         scale2=widgets.FloatSlider(value=1, min=0.1, max=10, step=0.1, description='Scale 2'),\n",
    "         size=widgets.IntSlider(value=100, min=50, max=500, step=50, description='Sample Size'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2deeb38-21d9-4993-b098-8c7d7364b9d7",
   "metadata": {},
   "source": [
    "### Wilcoxon impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "094e1ab2-17f1-416e-a905-a98b369b0b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Wilcoxon Test Results\n",
      "W: 34.5\n",
      "Expected W: 27.5\n",
      "Standard Deviation of W: 4.7871355387816905\n",
      "z-score: 1.462252310027862\n",
      "p-value (from z-score): 0.14367208180696034\n",
      "\n",
      "Scipy Wilcoxon Test Results\n",
      "U-statistic: 22.0\n",
      "Converted W from U: 37.0\n",
      "p-value (scipy): 0.05555555555555555\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu\n",
    "from math import erf, sqrt\n",
    "\n",
    "# Manual Wilcoxon Rank Sum Test Implementation\n",
    "def wilcoxon_rank_sum_test_manual(X, Y):\n",
    "    # Combine the samples\n",
    "    combined = np.concatenate([X, Y])\n",
    "    labels = np.array([1] * len(X) + [2] * len(Y))  # Label sample X with 1, Y with 2\n",
    "    \n",
    "    # Sort combined data and assign ranks\n",
    "    sorted_indices = np.argsort(combined)\n",
    "    ranks = np.zeros_like(combined, dtype=float)\n",
    "    \n",
    "    # Assign ranks (average ranks for ties)\n",
    "    i = 0\n",
    "    while i < len(combined):\n",
    "        start = i\n",
    "        while i + 1 < len(combined) and combined[sorted_indices[i]] == combined[sorted_indices[i + 1]]:\n",
    "            i += 1\n",
    "        rank = (start + i + 1) / 2.0  # Average rank for tied values\n",
    "        for j in range(start, i + 1):\n",
    "            ranks[sorted_indices[j]] = rank\n",
    "        i += 1\n",
    "\n",
    "    # Calculate W (sum of ranks for sample X)\n",
    "    W_X = np.sum(ranks[labels == 1])\n",
    "    \n",
    "    # Expected value and variance of W under H0\n",
    "    n, m = len(X), len(Y)\n",
    "    mu_W = n * (n + m + 1) / 2\n",
    "    sigma_W = np.sqrt(n * m * (n + m + 1) / 12)\n",
    "    \n",
    "    # Calculate z-score for the test statistic\n",
    "    z = (W_X - mu_W) / sigma_W\n",
    "    \n",
    "    # Convert z-score to p-value for a two-tailed test\n",
    "    p_value_manual = 2 * (1 - 0.5 * (1 + erf(abs(z) / sqrt(2))))\n",
    "    \n",
    "    return W_X, mu_W, sigma_W, z, p_value_manual\n",
    "\n",
    "# Wilcoxon Rank Sum Test using scipy\n",
    "def wilcoxon_rank_sum_test_scipy(X, Y):\n",
    "    u_statistic, p_value = mannwhitneyu(X, Y, alternative='two-sided')\n",
    "    # Convert U to W for comparison\n",
    "    W_converted = u_statistic + len(X) * (len(X) + 1) / 2\n",
    "    return u_statistic, W_converted, p_value\n",
    "\n",
    "# Comparison function\n",
    "def compare_tests(X, Y):\n",
    "    # Manual implementation\n",
    "    W_X_manual, mu_W_manual, sigma_W_manual, z_manual, p_value_manual = wilcoxon_rank_sum_test_manual(X, Y)\n",
    "    # Scipy implementation\n",
    "    u_statistic_scipy, W_scipy_converted, p_value_scipy = wilcoxon_rank_sum_test_scipy(X, Y)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"Manual Wilcoxon Test Results\")\n",
    "    print(f\"W: {W_X_manual}\")\n",
    "    print(f\"Expected W: {mu_W_manual}\")\n",
    "    print(f\"Standard Deviation of W: {sigma_W_manual}\")\n",
    "    print(f\"z-score: {z_manual}\")\n",
    "    print(f\"p-value (from z-score): {p_value_manual}\")\n",
    "    \n",
    "    print(\"\\nScipy Wilcoxon Test Results\")\n",
    "    print(f\"U-statistic: {u_statistic_scipy}\")\n",
    "    print(f\"Converted W from U: {W_scipy_converted}\")\n",
    "    print(f\"p-value (scipy): {p_value_scipy}\")\n",
    "\n",
    "# Example usage\n",
    "X = np.array([2.5, 3.6, 3.1, 4.4, 3.2])  # Sample X\n",
    "Y = np.array([1.2, 2.1, 2.4, 2.3, 3.5])  # Sample Y\n",
    "\n",
    "# Run comparison\n",
    "compare_tests(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34899232-28b0-41b9-a097-7bcdae173de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from scipy import special\n",
    "from scipy import stats\n",
    "\n",
    "def _order_ranks(ranks, j):\n",
    "    # Reorder ascending order `ranks` according to `j`\n",
    "    ordered_ranks = np.empty(j.shape, dtype=ranks.dtype)\n",
    "    np.put_along_axis(ordered_ranks, j, ranks, axis=-1)\n",
    "    return ordered_ranks\n",
    "\n",
    "def _rankdata(x, method, return_ties=False):\n",
    "    shape = x.shape\n",
    "\n",
    "    kind = 'mergesort' if method == 'ordinal' else 'quicksort'\n",
    "    j = np.argsort(x, axis=-1, kind=kind)\n",
    "    ordinal_ranks = np.broadcast_to(np.arange(1, shape[-1]+1, dtype=int), shape)\n",
    "\n",
    "    if method == 'ordinal':\n",
    "        return _order_ranks(ordinal_ranks, j)  # never return ties\n",
    "\n",
    "    y = np.take_along_axis(x, j, axis=-1)\n",
    "    i = np.concatenate([np.ones(shape[:-1] + (1,), dtype=np.bool_),\n",
    "                       y[..., :-1] != y[..., 1:]], axis=-1)\n",
    "\n",
    "    indices = np.arange(y.size)[i.ravel()]\n",
    "    counts = np.diff(indices, append=y.size)\n",
    "\n",
    "    if method == 'min':\n",
    "        ranks = ordinal_ranks[i]\n",
    "    elif method == 'max':\n",
    "        ranks = ordinal_ranks[i] + counts - 1\n",
    "    elif method == 'average':\n",
    "        ranks = ordinal_ranks[i] + (counts - 1)/2\n",
    "    elif method == 'dense':\n",
    "        ranks = np.cumsum(i, axis=-1)[i]\n",
    "\n",
    "    ranks = np.repeat(ranks, counts).reshape(shape)\n",
    "    ranks = _order_ranks(ranks, j)\n",
    "\n",
    "    if return_ties:\n",
    "        t = np.zeros(shape, dtype=float)\n",
    "        t[i] = counts\n",
    "        return ranks, t\n",
    "    return ranks\n",
    "\n",
    "def _broadcast_concatenate(x, y, axis):\n",
    "    '''Broadcast then concatenate arrays, leaving concatenation axis last'''\n",
    "    x = np.moveaxis(x, axis, -1)\n",
    "    y = np.moveaxis(y, axis, -1)\n",
    "    z = np.broadcast(x[..., 0], y[..., 0])\n",
    "    x = np.broadcast_to(x, z.shape + (x.shape[-1],))\n",
    "    y = np.broadcast_to(y, z.shape + (y.shape[-1],))\n",
    "    z = np.concatenate((x, y), axis=-1)\n",
    "    return x, y, z\n",
    "\n",
    "\n",
    "class _MWU:\n",
    "    '''Distribution of MWU statistic under the null hypothesis'''\n",
    "\n",
    "    def __init__(self, n1, n2):\n",
    "        self._reset(n1, n2)\n",
    "\n",
    "    def set_shapes(self, n1, n2):\n",
    "        n1, n2 = min(n1, n2), max(n1, n2)\n",
    "        if (n1, n2) == (self.n1, self.n2):\n",
    "            return\n",
    "\n",
    "        self.n1 = n1\n",
    "        self.n2 = n2\n",
    "        self.s_array = np.zeros(0, dtype=int)\n",
    "        self.configurations = np.zeros(0, dtype=np.uint64)\n",
    "\n",
    "    def reset(self):\n",
    "        self._reset(self.n1, self.n2)\n",
    "\n",
    "    def _reset(self, n1, n2):\n",
    "        self.n1 = None\n",
    "        self.n2 = None\n",
    "        self.set_shapes(n1, n2)\n",
    "\n",
    "    def pmf(self, k):\n",
    "        pmfs = self.build_u_freqs_array(np.max(k))\n",
    "        return pmfs[k]\n",
    "\n",
    "    def cdf(self, k):\n",
    "        '''Cumulative distribution function'''\n",
    "        pmfs = self.build_u_freqs_array(np.max(k))\n",
    "        cdfs = np.cumsum(pmfs)\n",
    "        return cdfs[k]\n",
    "\n",
    "    def sf(self, k):\n",
    "        '''Survival function'''\n",
    "        kc = np.asarray(self.n1*self.n2 - k)  # complement of k\n",
    "        i = k < kc\n",
    "        if np.any(i):\n",
    "            kc[i] = k[i]\n",
    "            cdfs = np.asarray(self.cdf(kc))\n",
    "            cdfs[i] = 1. - cdfs[i] + self.pmf(kc[i])\n",
    "        else:\n",
    "            cdfs = np.asarray(self.cdf(kc))\n",
    "        return cdfs[()]\n",
    "\n",
    "    # build_sigma_array and build_u_freqs_array adapted from code\n",
    "    # by @toobaz with permission. Thanks to @andreasloe for the suggestion.\n",
    "    # See https://github.com/scipy/scipy/pull/4933#issuecomment-1898082691\n",
    "    def build_sigma_array(self, a):\n",
    "        n1, n2 = self.n1, self.n2\n",
    "        if a + 1 <= self.s_array.size:\n",
    "            return self.s_array[1:a+1]\n",
    "\n",
    "        s_array = np.zeros(a + 1, dtype=int)\n",
    "\n",
    "        for d in np.arange(1, n1 + 1):\n",
    "            # All multiples of d, except 0:\n",
    "            indices = np.arange(d, a + 1, d)\n",
    "            # \\epsilon_d = 1:\n",
    "            s_array[indices] += d\n",
    "\n",
    "        for d in np.arange(n2 + 1, n2 + n1 + 1):\n",
    "            # All multiples of d, except 0:\n",
    "            indices = np.arange(d, a + 1, d)\n",
    "            # \\epsilon_d = -1:\n",
    "            s_array[indices] -= d\n",
    "\n",
    "        # We don't need 0:\n",
    "        self.s_array = s_array\n",
    "        return s_array[1:]\n",
    "\n",
    "    def build_u_freqs_array(self, maxu):\n",
    "        \"\"\"\n",
    "        Build all the array of frequencies for u from 0 to maxu.\n",
    "        Assumptions:\n",
    "          n1 <= n2\n",
    "          maxu <= n1 * n2 / 2\n",
    "        \"\"\"\n",
    "        n1, n2 = self.n1, self.n2\n",
    "        total = special.binom(n1 + n2, n1)\n",
    "\n",
    "        if maxu + 1 <= self.configurations.size:\n",
    "            return self.configurations[:maxu + 1] / total\n",
    "\n",
    "        s_array = self.build_sigma_array(maxu)\n",
    "\n",
    "        # Start working with ints, for maximum precision and efficiency:\n",
    "        configurations = np.zeros(maxu + 1, dtype=np.uint64)\n",
    "        configurations_is_uint = True\n",
    "        uint_max = np.iinfo(np.uint64).max\n",
    "        # How many ways to have U=0? 1\n",
    "        configurations[0] = 1\n",
    "\n",
    "        for u in np.arange(1, maxu + 1):\n",
    "            coeffs = s_array[u - 1::-1]\n",
    "            new_val = np.dot(configurations[:u], coeffs) / u\n",
    "            if new_val > uint_max and configurations_is_uint:\n",
    "                # OK, we got into numbers too big for uint64.\n",
    "                # So now we start working with floats.\n",
    "                # By doing this since the beginning, we would have lost precision.\n",
    "                # (And working on python long ints would be unbearably slow)\n",
    "                configurations = configurations.astype(float)\n",
    "                configurations_is_uint = False\n",
    "            configurations[u] = new_val\n",
    "\n",
    "        self.configurations = configurations\n",
    "        return configurations / total\n",
    "\n",
    "\n",
    "_mwu_state = _MWU(0, 0)\n",
    "\n",
    "\n",
    "def _get_mwu_z(U, n1, n2, t, axis=0, continuity=True):\n",
    "    '''Standardized MWU statistic'''\n",
    "    # Follows mannwhitneyu [2]\n",
    "    mu = n1 * n2 / 2\n",
    "    n = n1 + n2\n",
    "\n",
    "    # Tie correction according to [2], \"Normal approximation and tie correction\"\n",
    "    # \"A more computationally-efficient form...\"\n",
    "    tie_term = (t**3 - t).sum(axis=-1)\n",
    "    s = np.sqrt(n1*n2/12 * ((n + 1) - tie_term/(n*(n-1))))\n",
    "\n",
    "    numerator = U - mu\n",
    "\n",
    "    # Continuity correction.\n",
    "    # Because SF is always used to calculate the p-value, we can always\n",
    "    # _subtract_ 0.5 for the continuity correction. This always increases the\n",
    "    # p-value to account for the rest of the probability mass _at_ q = U.\n",
    "    if continuity:\n",
    "        numerator -= 0.5\n",
    "\n",
    "    # no problem evaluating the norm SF at an infinity\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        z = numerator / s\n",
    "    return z\n",
    "\n",
    "\n",
    "def _mwu_input_validation(x, y, use_continuity, alternative, axis, method):\n",
    "    ''' Input validation and standardization for mannwhitneyu '''\n",
    "    # Would use np.asarray_chkfinite, but infs are OK\n",
    "    x, y = np.atleast_1d(x), np.atleast_1d(y)\n",
    "    if np.isnan(x).any() or np.isnan(y).any():\n",
    "        raise ValueError('`x` and `y` must not contain NaNs.')\n",
    "    if np.size(x) == 0 or np.size(y) == 0:\n",
    "        raise ValueError('`x` and `y` must be of nonzero size.')\n",
    "\n",
    "    bools = {True, False}\n",
    "    if use_continuity not in bools:\n",
    "        raise ValueError(f'`use_continuity` must be one of {bools}.')\n",
    "\n",
    "    alternatives = {\"two-sided\", \"less\", \"greater\"}\n",
    "    alternative = alternative.lower()\n",
    "    if alternative not in alternatives:\n",
    "        raise ValueError(f'`alternative` must be one of {alternatives}.')\n",
    "\n",
    "    axis_int = int(axis)\n",
    "    if axis != axis_int:\n",
    "        raise ValueError('`axis` must be an integer.')\n",
    "\n",
    "    if not isinstance(method, stats.PermutationMethod):\n",
    "        methods = {\"asymptotic\", \"exact\", \"auto\"}\n",
    "        method = method.lower()\n",
    "        if method not in methods:\n",
    "            raise ValueError(f'`method` must be one of {methods}.')\n",
    "\n",
    "    return x, y, use_continuity, alternative, axis_int, method\n",
    "\n",
    "\n",
    "def _mwu_choose_method(n1, n2, ties):\n",
    "    \"\"\"Choose method 'asymptotic' or 'exact' depending on input size, ties\"\"\"\n",
    "\n",
    "    # if both inputs are large, asymptotic is OK\n",
    "    if n1 > 8 and n2 > 8:\n",
    "        return \"asymptotic\"\n",
    "\n",
    "    # if there are any ties, asymptotic is preferred\n",
    "    if ties:\n",
    "        return \"asymptotic\"\n",
    "\n",
    "    return \"exact\"\n",
    "\n",
    "\n",
    "MannwhitneyuResult = namedtuple('MannwhitneyuResult', ('statistic', 'pvalue'))\n",
    "\n",
    "\n",
    "def mannwhitneyu(x, y, use_continuity=True, alternative=\"two-sided\",\n",
    "                 axis=0, method=\"auto\"):\n",
    "\n",
    "    x, y, use_continuity, alternative, axis_int, method = (\n",
    "        _mwu_input_validation(x, y, use_continuity, alternative, axis, method))\n",
    "\n",
    "    x, y, xy = _broadcast_concatenate(x, y, axis)\n",
    "\n",
    "    n1, n2 = x.shape[-1], y.shape[-1]\n",
    "\n",
    "    # Follows [2]\n",
    "    ranks, t = _rankdata(xy, 'average', return_ties=True)  # method 2, step 1\n",
    "    R1 = ranks[..., :n1].sum(axis=-1)                      # method 2, step 2\n",
    "    U1 = R1 - n1*(n1+1)/2                                  # method 2, step 3\n",
    "    U2 = n1 * n2 - U1                                      # as U1 + U2 = n1 * n2\n",
    "\n",
    "    if alternative == \"greater\":\n",
    "        U, f = U1, 1  # U is the statistic to use for p-value, f is a factor\n",
    "    elif alternative == \"less\":\n",
    "        U, f = U2, 1  # Due to symmetry, use SF of U2 rather than CDF of U1\n",
    "    else:\n",
    "        U, f = np.maximum(U1, U2), 2  # multiply SF by two for two-sided test\n",
    "\n",
    "    if method == \"auto\":\n",
    "        method = _mwu_choose_method(n1, n2, np.any(t > 1))\n",
    "\n",
    "    if method == \"exact\":\n",
    "        _mwu_state.set_shapes(n1, n2)\n",
    "        p = _mwu_state.sf(U.astype(int))\n",
    "    elif method == \"asymptotic\":\n",
    "        z = _get_mwu_z(U, n1, n2, t, continuity=use_continuity)\n",
    "        p = stats.norm.sf(z)\n",
    "    else:  # `PermutationMethod` instance (already validated)\n",
    "        def statistic(x, y, axis):\n",
    "            return mannwhitneyu(x, y, use_continuity=use_continuity,\n",
    "                                alternative=alternative, axis=axis,\n",
    "                                method=\"asymptotic\").statistic\n",
    "\n",
    "        res = stats.permutation_test((x, y), statistic, axis=axis,\n",
    "                                     **method._asdict(), alternative=alternative)\n",
    "        p = res.pvalue\n",
    "        f = 1\n",
    "\n",
    "    p *= f\n",
    "\n",
    "    # Ensure that test statistic is not greater than 1\n",
    "    # This could happen for exact test when U = m*n/2\n",
    "    p = np.clip(p, 0, 1)\n",
    "\n",
    "    return MannwhitneyuResult(U1, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7657e094-c48b-41b8-ba0d-2469a5c7e448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=32960.0, pvalue=1.4217284932393384e-08)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "sample1 = np.random.normal(loc=50, scale=10, size=300)\n",
    "sample2 = np.random.normal(loc=60, scale=20, size=300)\n",
    "\n",
    "mannwhitneyu(sample1, sample2, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33606114-13c6-4732-889e-880443b38037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=32960.0, pvalue=1.4217284932393384e-08)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "sample1 = np.random.normal(loc=50, scale=10, size=300)\n",
    "sample2 = np.random.normal(loc=60, scale=20, size=300)\n",
    "\n",
    "mannwhitneyu(sample1, sample2, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01b93c9f-cba4-44cc-9709-b7efee744c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from scipy import special, stats\n",
    "# taken from scipy's library\n",
    "\n",
    "def _order_ranks(ranks, indices):\n",
    "    \"\"\"Reorder ranks according to indices.\"\"\"\n",
    "    ordered_ranks = np.empty_like(ranks)\n",
    "    np.put_along_axis(ordered_ranks, indices, ranks, axis=-1)\n",
    "    return ordered_ranks\n",
    "\n",
    "\n",
    "def _rankdata(x, method, return_ties=False):\n",
    "    \"\"\"Rank data with different ranking methods.\"\"\"\n",
    "    shape = x.shape\n",
    "    kind = 'mergesort' if method == 'ordinal' else 'quicksort'\n",
    "    indices = np.argsort(x, axis=-1, kind=kind)\n",
    "    ranks = np.broadcast_to(np.arange(1, shape[-1] + 1), shape)\n",
    "\n",
    "    if method == 'ordinal':\n",
    "        return _order_ranks(ranks, indices)\n",
    "\n",
    "    y = np.take_along_axis(x, indices, axis=-1)\n",
    "    diff = np.concatenate([np.ones_like(y[..., :1], dtype=bool), y[..., :-1] != y[..., 1:]], axis=-1)\n",
    "    counts = np.diff(np.flatnonzero(diff), append=y.size)\n",
    "\n",
    "    if method == 'min':\n",
    "        ranks = ranks[diff]\n",
    "    elif method == 'max':\n",
    "        ranks = ranks[diff] + counts - 1\n",
    "    elif method == 'average':\n",
    "        ranks = ranks[diff] + (counts - 1) / 2\n",
    "    elif method == 'dense':\n",
    "        ranks = np.cumsum(diff, axis=-1)[diff]\n",
    "\n",
    "    ranks = np.repeat(ranks, counts).reshape(shape)\n",
    "    ranks = _order_ranks(ranks, indices)\n",
    "\n",
    "    if return_ties:\n",
    "        ties = np.zeros_like(x, dtype=float)\n",
    "        ties[diff] = counts\n",
    "        return ranks, ties\n",
    "\n",
    "    return ranks\n",
    "\n",
    "\n",
    "def _broadcast_concatenate(x, y, axis):\n",
    "    \"\"\"Broadcast and concatenate arrays along the last axis.\"\"\"\n",
    "    x, y = np.moveaxis(x, axis, -1), np.moveaxis(y, axis, -1)\n",
    "    shape = np.broadcast(x[..., 0], y[..., 0]).shape\n",
    "    x = np.broadcast_to(x, shape + (x.shape[-1],))\n",
    "    y = np.broadcast_to(y, shape + (y.shape[-1],))\n",
    "    return x, y, np.concatenate((x, y), axis=-1)\n",
    "\n",
    "\n",
    "class _MWU:\n",
    "    \"\"\"Distribution of MWU statistic under the null hypothesis.\"\"\"\n",
    "    def __init__(self, n1, n2):\n",
    "        self.n1, self.n2 = None, None\n",
    "        self.set_shapes(n1, n2)\n",
    "\n",
    "    def set_shapes(self, n1, n2):\n",
    "        self.n1, self.n2 = sorted((n1, n2))\n",
    "        self.s_array = np.zeros(0, dtype=int)\n",
    "        self.configurations = np.zeros(0, dtype=np.uint64)\n",
    "\n",
    "    def pmf(self, k):\n",
    "        return self._build_u_freqs_array(np.max(k))[k]\n",
    "\n",
    "    def cdf(self, k):\n",
    "        pmfs = self._build_u_freqs_array(np.max(k))\n",
    "        return np.cumsum(pmfs)[k]\n",
    "\n",
    "    def _build_u_freqs_array(self, maxu):\n",
    "        \"\"\"Build frequency array for MWU statistic.\"\"\"\n",
    "        total = special.binom(self.n1 + self.n2, self.n1)\n",
    "        s_array = self._build_sigma_array(maxu)\n",
    "\n",
    "        configurations = np.zeros(maxu + 1, dtype=np.uint64)\n",
    "        configurations[0] = 1\n",
    "\n",
    "        for u in range(1, maxu + 1):\n",
    "            coeffs = s_array[u - 1::-1]\n",
    "            configurations[u] = np.dot(configurations[:u], coeffs) // u\n",
    "\n",
    "        self.configurations = configurations\n",
    "        return configurations / total\n",
    "\n",
    "    def _build_sigma_array(self, maxa):\n",
    "        \"\"\"Build sigma array for MWU statistic.\"\"\"\n",
    "        if maxa < len(self.s_array):\n",
    "            return self.s_array[:maxa + 1]\n",
    "\n",
    "        s_array = np.zeros(maxa + 1, dtype=int)\n",
    "        for d in range(1, self.n1 + 1):\n",
    "            s_array[d::d] += d\n",
    "        for d in range(self.n2 + 1, self.n2 + self.n1 + 1):\n",
    "            s_array[d::d] -= d\n",
    "\n",
    "        self.s_array = s_array\n",
    "        return s_array\n",
    "\n",
    "\n",
    "def _mwu_choose_method(n1, n2, ties):\n",
    "    \"\"\"Choose MWU method based on input size and ties.\"\"\"\n",
    "    if n1 > 8 and n2 > 8 or ties:\n",
    "        return \"asymptotic\"\n",
    "    return \"exact\"\n",
    "\n",
    "\n",
    "def _get_mwu_z(U, n1, n2, t, continuity=True):\n",
    "    \"\"\"Calculate standardized MWU statistic.\"\"\"\n",
    "    n, mu = n1 + n2, n1 * n2 / 2\n",
    "    s = np.sqrt(n1 * n2 / 12 * ((n + 1) - (t**3 - t).sum() / (n * (n - 1))))\n",
    "    return (U - mu - (0.5 if continuity else 0)) / s\n",
    "\n",
    "\n",
    "MannwhitneyuResult = namedtuple('MannwhitneyuResult', ('statistic', 'pvalue'))\n",
    "\n",
    "\n",
    "def mannwhitneyu(x, y, use_continuity=True, alternative=\"two-sided\", axis=0, method=\"auto\"):\n",
    "    x, y, xy = _broadcast_concatenate(np.asarray(x), np.asarray(y), axis)\n",
    "    n1, n2 = x.shape[-1], y.shape[-1]\n",
    "    ranks, ties = _rankdata(xy, 'average', return_ties=True)\n",
    "    U1 = ranks[..., :n1].sum(axis=-1) - n1 * (n1 + 1) / 2\n",
    "    U2 = n1 * n2 - U1\n",
    "    U = U1 if alternative == \"greater\" else U2 if alternative == \"less\" else np.maximum(U1, U2)\n",
    "\n",
    "    if method == \"auto\":\n",
    "        method = _mwu_choose_method(n1, n2, np.any(ties > 1))\n",
    "\n",
    "    if method == \"exact\":\n",
    "        _mwu_state = _MWU(n1, n2)\n",
    "        p = _mwu_state.pmf(U.astype(int))\n",
    "    elif method == \"asymptotic\":\n",
    "        z = _get_mwu_z(U, n1, n2, ties, continuity=use_continuity)\n",
    "        p = stats.norm.sf(z) * (2 if alternative == \"two-sided\" else 1)\n",
    "\n",
    "    return MannwhitneyuResult(U1, np.clip(p, 0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de59780e-fb42-49a1-821c-5dd318117c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=32960.0, pvalue=1.4217284932393384e-08)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "sample1 = np.random.normal(loc=50, scale=10, size=300)\n",
    "sample2 = np.random.normal(loc=60, scale=20, size=300)\n",
    "\n",
    "mannwhitneyu(sample1, sample2, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3fc1662-18f3-4146-9aff-af9940b57270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm, chi2\n",
    "\n",
    "def van_der_waerden_test(*samples):\n",
    "    \"\"\"\n",
    "    Perform the Van der Waerden test for k independent samples.\n",
    "\n",
    "    Parameters:\n",
    "    *samples : array-like\n",
    "        Variable number of arrays, each representing an independent sample.\n",
    "\n",
    "    Returns:\n",
    "    statistic : float\n",
    "        The test statistic.\n",
    "    p_value : float\n",
    "        The p-value of the test.\n",
    "    \"\"\"\n",
    "    # Combine all samples into a single array\n",
    "    data = np.concatenate(samples)\n",
    "    n_total = len(data)\n",
    "    k = len(samples)\n",
    "    sample_sizes = [len(sample) for sample in samples]\n",
    "\n",
    "    # Rank the combined data\n",
    "    ranks = np.argsort(np.argsort(data)) + 1\n",
    "\n",
    "    # Compute normal scores\n",
    "    normal_scores = norm.ppf((ranks - 0.5) / n_total)\n",
    "\n",
    "    # Calculate the sum of normal scores for each sample\n",
    "    sum_scores = []\n",
    "    start = 0\n",
    "    for size in sample_sizes:\n",
    "        sum_scores.append(np.sum(normal_scores[start:start + size]))\n",
    "        start += size\n",
    "\n",
    "    # Compute the test statistic\n",
    "    sum_scores = np.array(sum_scores)\n",
    "    n_i = np.array(sample_sizes)\n",
    "    A_bar = sum_scores / n_i\n",
    "    A_bar_total = np.sum(sum_scores) / n_total\n",
    "    S_square = np.sum((normal_scores - A_bar_total) ** 2) / (n_total - 1)\n",
    "    T = np.sum(n_i * (A_bar - A_bar_total) ** 2) / S_square\n",
    "\n",
    "    # Calculate the p-value\n",
    "    p_value = 1 - chi2.cdf(T, k - 1)\n",
    "\n",
    "    return T, p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79a53f18-2991-46e2-b41f-7a294a6a6c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 26.299182518063674\n",
      "P-Value: 2.9241242149868896e-07\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "sample1 = np.random.normal(loc=50, scale=10, size=300)\n",
    "sample2 = np.random.normal(loc=60, scale=20, size=300)\n",
    "statistic, p_value = van_der_waerden_test(sample1, sample2)\n",
    "print(f\"Test Statistic: {statistic}\")\n",
    "print(f\"P-Value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3e47837-184e-4ea1-a020-9a7598fd13f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def median_test(*samples):\n",
    "    \"\"\"\n",
    "    Perform the Median Test for k independent samples.\n",
    "\n",
    "    Parameters:\n",
    "    *samples : array-like\n",
    "        Variable number of arrays, each representing an independent sample.\n",
    "\n",
    "    Returns:\n",
    "    statistic : float\n",
    "        The test statistic.\n",
    "    p_value : float\n",
    "        The p-value of the test.\n",
    "    \"\"\"\n",
    "    # Combine all samples into a single array\n",
    "    data = np.concatenate(samples)\n",
    "    grand_median = np.median(data)\n",
    "\n",
    "    # Create a contingency table\n",
    "    contingency_table = []\n",
    "    for sample in samples:\n",
    "        above_median = np.sum(sample > grand_median)\n",
    "        below_or_equal_median = np.sum(sample <= grand_median)\n",
    "        contingency_table.append([above_median, below_or_equal_median])\n",
    "\n",
    "    # Perform the chi-squared test\n",
    "    contingency_table = np.array(contingency_table)\n",
    "    chi2, p_value, _, _ = chi2_contingency(contingency_table, correction=False)\n",
    "\n",
    "    return chi2, p_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d95ea8a2-5669-4f95-8fd2-ef46341cb177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 22.426666666666666\n",
      "P-Value: 2.183216533714857e-06\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "sample1 = np.random.normal(loc=50, scale=10, size=300)\n",
    "sample2 = np.random.normal(loc=60, scale=20, size=300)\n",
    "\n",
    "statistic, p_value = median_test(sample1, sample2)\n",
    "print(f\"Test Statistic: {statistic}\")\n",
    "print(f\"P-Value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46c01eaa-9f6f-48c1-bd12-d6b39a8445e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 26.299182518063674\n",
      "P-Value: 2.9241242149868896e-07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm, chi2\n",
    "\n",
    "def fisher_yates_terry_hoeffding_test(*samples):\n",
    "    \"\"\"\n",
    "    Perform the Fisher-Yates-Terry-Hoeffding (FYTH) test for k independent samples.\n",
    "\n",
    "    Parameters:\n",
    "    *samples : array-like\n",
    "        Variable number of arrays, each representing an independent sample.\n",
    "\n",
    "    Returns:\n",
    "    statistic : float\n",
    "        The test statistic.\n",
    "    p_value : float\n",
    "        The p-value of the test.\n",
    "    \"\"\"\n",
    "    # Combine all samples into a single array\n",
    "    data = np.concatenate(samples)\n",
    "    n_total = len(data)\n",
    "    k = len(samples)\n",
    "    sample_sizes = [len(sample) for sample in samples]\n",
    "\n",
    "    # Rank the combined data\n",
    "    ranks = np.argsort(np.argsort(data)) + 1\n",
    "\n",
    "    # Compute expected normal scores\n",
    "    expected_normal_scores = norm.ppf((ranks - 0.5) / n_total)\n",
    "\n",
    "    # Calculate the sum of expected normal scores for each sample\n",
    "    sum_scores = []\n",
    "    start = 0\n",
    "    for size in sample_sizes:\n",
    "        sum_scores.append(np.sum(expected_normal_scores[start:start + size]))\n",
    "        start += size\n",
    "\n",
    "    # Compute the test statistic\n",
    "    sum_scores = np.array(sum_scores)\n",
    "    n_i = np.array(sample_sizes)\n",
    "    A_bar = sum_scores / n_i\n",
    "    A_bar_total = np.sum(sum_scores) / n_total\n",
    "    S_square = np.sum((expected_normal_scores - A_bar_total) ** 2) / (n_total - 1)\n",
    "    T = np.sum(n_i * (A_bar - A_bar_total) ** 2) / S_square\n",
    "\n",
    "    # Calculate the p-value\n",
    "    p_value = 1 - chi2.cdf(T, k - 1)\n",
    "\n",
    "    return T, p_value\n",
    "\n",
    "np.random.seed(0)\n",
    "sample1 = np.random.normal(loc=50, scale=10, size=300)\n",
    "sample2 = np.random.normal(loc=60, scale=20, size=300)\n",
    "\n",
    "statistic, p_value = fisher_yates_terry_hoeffding_test(sample1, sample2)\n",
    "print(f\"Test Statistic: {statistic}\")\n",
    "print(f\"P-Value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "035c3c96-467e-4273-b5f5-3da5bc67125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Difference: -6.9760915657594325\n",
      "P-Value: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def permutation_test(sample1, sample2, num_permutations=10000, alternative='two-sided'):\n",
    "    \"\"\"\n",
    "    Perform a permutation test to compare two independent samples.\n",
    "\n",
    "    Parameters:\n",
    "    sample1 : array-like\n",
    "        First sample data.\n",
    "    sample2 : array-like\n",
    "        Second sample data.\n",
    "    num_permutations : int, optional\n",
    "        Number of permutations to perform (default is 10,000).\n",
    "    alternative : {'two-sided', 'greater', 'less'}, optional\n",
    "        Defines the alternative hypothesis (default is 'two-sided').\n",
    "\n",
    "    Returns:\n",
    "    p_value : float\n",
    "        The p-value of the test.\n",
    "    observed_diff : float\n",
    "        The observed difference in means between the two samples.\n",
    "    \"\"\"\n",
    "    # Combine the data\n",
    "    combined = np.concatenate([sample1, sample2])\n",
    "    n1 = len(sample1)\n",
    "    observed_diff = np.mean(sample1) - np.mean(sample2)\n",
    "\n",
    "    # Generate permutation samples\n",
    "    perm_diffs = np.zeros(num_permutations)\n",
    "    for i in range(num_permutations):\n",
    "        np.random.shuffle(combined)\n",
    "        perm_sample1 = combined[:n1]\n",
    "        perm_sample2 = combined[n1:]\n",
    "        perm_diffs[i] = np.mean(perm_sample1) - np.mean(perm_sample2)\n",
    "\n",
    "    # Calculate p-value\n",
    "    if alternative == 'two-sided':\n",
    "        p_value = np.mean(np.abs(perm_diffs) >= np.abs(observed_diff))\n",
    "    elif alternative == 'greater':\n",
    "        p_value = np.mean(perm_diffs >= observed_diff)\n",
    "    elif alternative == 'less':\n",
    "        p_value = np.mean(perm_diffs <= observed_diff)\n",
    "    else:\n",
    "        raise ValueError(\"alternative must be 'two-sided', 'greater', or 'less'\")\n",
    "\n",
    "    return p_value, observed_diff\n",
    "\n",
    "np.random.seed(0)\n",
    "sample1 = np.random.normal(loc=50, scale=10, size=300)\n",
    "sample2 = np.random.normal(loc=60, scale=20, size=300)\n",
    "\n",
    "p_value, observed_diff = permutation_test(sample1, sample2, alternative='two-sided')\n",
    "print(f\"Observed Difference: {observed_diff}\")\n",
    "print(f\"P-Value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2dc0431-34b7-4d56-b13e-cd7d10632b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: -5.3959889747439895\n",
      "P-Value: 1.115761051138561e-07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def two_sample_t_test(sample1, sample2, equal_var=True, alternative='two-sided'):\n",
    "    \"\"\"\n",
    "    Perform a two-sample t-test to compare the means of two independent samples.\n",
    "\n",
    "    Parameters:\n",
    "    sample1 : array-like\n",
    "        First sample data.\n",
    "    sample2 : array-like\n",
    "        Second sample data.\n",
    "    equal_var : bool, optional\n",
    "        If True (default), perform a standard independent 2 sample t-test that assumes equal population variances.\n",
    "        If False, perform Welch’s t-test, which does not assume equal population variances.\n",
    "    alternative : {'two-sided', 'less', 'greater'}, optional\n",
    "        Defines the alternative hypothesis (default is 'two-sided').\n",
    "\n",
    "    Returns:\n",
    "    statistic : float\n",
    "        The calculated t-statistic.\n",
    "    p_value : float\n",
    "        The p-value of the test.\n",
    "    \"\"\"\n",
    "    # Perform the t-test\n",
    "    t_stat, p_value = ttest_ind(sample1, sample2, equal_var=equal_var, alternative=alternative)\n",
    "    return t_stat, p_value\n",
    "\n",
    "np.random.seed(0)\n",
    "sample1 = np.random.normal(loc=50, scale=10, size=300)\n",
    "sample2 = np.random.normal(loc=60, scale=20, size=300)\n",
    "\n",
    "t_stat, p_value = two_sample_t_test(sample1, sample2, equal_var=False, alternative='two-sided')\n",
    "print(f\"T-Statistic: {t_stat}\")\n",
    "print(f\"P-Value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338cf6f6-74c9-46b6-a764-c77cb9f4e258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
